{"cells":[{"metadata":{"id":"-8-iDTZf-uh_","colab_type":"code","outputId":"10a8f310-41d7-4fc5-9035-342c498c6ac0","colab":{"base_uri":"https://localhost:8080/","height":330},"trusted":true},"cell_type":"code","source":"from keras import models\nfrom keras import layers\nfrom keras import optimizers\nfrom keras.applications import VGG16\nimport numpy\nimport keras\nimport matplotlib.pyplot\n#Load the VGG model\nvgg_conv = VGG16(weights='imagenet', include_top=False, input_shape=(332, 332, 3))\n# Create the model\n# Freeze the layers except the last 4 layers\nfor layer in vgg_conv.layers[:-4]:\n    layer.trainable = False\n \n# Check the trainable status of the individual layers\nfor layer in vgg_conv.layers:\n    print(layer, layer.trainable)\nmodel = models.Sequential()\n# Add the vgg convolutional base model\nmodel.add(vgg_conv)\n# Add new layers\nmodel.add(layers.Flatten())\nmodel.add(layers.Dense(512, activation='relu'))\nmodel.add(layers.Dropout(0.5))\nmodel.add(layers.Dense(512, activation='relu'))\nmodel.add(layers.Dropout(0.5))\nmodel.add(layers.Dense(6, activation='softmax'))\n\n# Show a summary of the model. Check the number of trainable parameters\nmodel.summary()","execution_count":13,"outputs":[{"output_type":"stream","text":"<keras.engine.input_layer.InputLayer object at 0x7ff770078320> False\n<keras.layers.convolutional.Conv2D object at 0x7ff770078a20> False\n<keras.layers.convolutional.Conv2D object at 0x7ff7700786d8> False\n<keras.layers.pooling.MaxPooling2D object at 0x7ff770078d68> False\n<keras.layers.convolutional.Conv2D object at 0x7ff770078b70> False\n<keras.layers.convolutional.Conv2D object at 0x7ff7d8c1c668> False\n<keras.layers.pooling.MaxPooling2D object at 0x7ff7d8a85780> False\n<keras.layers.convolutional.Conv2D object at 0x7ff7d8a85278> False\n<keras.layers.convolutional.Conv2D object at 0x7ff7144257b8> False\n<keras.layers.convolutional.Conv2D object at 0x7ff714528438> False\n<keras.layers.pooling.MaxPooling2D object at 0x7ff714528cf8> False\n<keras.layers.convolutional.Conv2D object at 0x7ff714528b38> False\n<keras.layers.convolutional.Conv2D object at 0x7ff71451d6a0> False\n<keras.layers.convolutional.Conv2D object at 0x7ff71451de48> False\n<keras.layers.pooling.MaxPooling2D object at 0x7ff714510978> False\n<keras.layers.convolutional.Conv2D object at 0x7ff7145107b8> True\n<keras.layers.convolutional.Conv2D object at 0x7ff7143bf320> True\n<keras.layers.convolutional.Conv2D object at 0x7ff7143bfcf8> True\n<keras.layers.pooling.MaxPooling2D object at 0x7ff7143ca5f8> True\nModel: \"sequential_3\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\nvgg16 (Model)                (None, 10, 10, 512)       14714688  \n_________________________________________________________________\nflatten_3 (Flatten)          (None, 51200)             0         \n_________________________________________________________________\ndense_6 (Dense)              (None, 512)               26214912  \n_________________________________________________________________\ndropout_4 (Dropout)          (None, 512)               0         \n_________________________________________________________________\ndense_7 (Dense)              (None, 512)               262656    \n_________________________________________________________________\ndropout_5 (Dropout)          (None, 512)               0         \n_________________________________________________________________\ndense_8 (Dense)              (None, 6)                 3078      \n=================================================================\nTotal params: 41,195,334\nTrainable params: 33,560,070\nNon-trainable params: 7,635,264\n_________________________________________________________________\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"import os\nbase_dir = '/kaggle/input/duth-cv-2019-2020-hw-4/vehicles'\ntrain_dir = os.path.join(base_dir, 'train')\nvalidation_dir = os.path.join(base_dir, 'val')","execution_count":14,"outputs":[]},{"metadata":{"id":"JruvtdJE9aoW","colab_type":"code","outputId":"5c881940-c6c8-472d-cfc5-c6d2ef8f3072","colab":{"base_uri":"https://localhost:8080/","height":52},"trusted":true},"cell_type":"code","source":"from tensorflow.keras.preprocessing.image import ImageDataGenerator\ntrain_dir2=os.path.join(train_dir, 'airplane/1382740959_a8eb7edb6c.jpg')\n\ntrain_datagen = ImageDataGenerator(rescale=1./255)\nval_datagen  = ImageDataGenerator(rescale=1./255)\nimg = keras.preprocessing.image.load_img(train_dir2)\nimg_array = keras.preprocessing.image.img_to_array(img)\n\nprint(img_array.shape, img_array.dtype)\n\n\n# --------------------\n# Flow training images in batches of 20 using train_datagen generator\n# --------------------\ntrain_generator = train_datagen.flow_from_directory(train_dir,\n                                                    batch_size=20,\n                                                    class_mode='categorical',\n                                                    #color_mode='grayscale',\n                                                    target_size=(332,332),\n                                                    shuffle=True)     \n# --------------------\n# Flow validation images in batches of 20 using test_datagen generator\n# --------------------\nvalidation_generator =  val_datagen.flow_from_directory(validation_dir,\n                                                        batch_size=20,\n                                                        class_mode='categorical',\n                                                       # color_mode='grayscale',\n                                                        target_size=(332,332)) ","execution_count":15,"outputs":[{"output_type":"stream","text":"(333, 499, 3) float32\nFound 2494 images belonging to 6 classes.\nFound 311 images belonging to 6 classes.\n","name":"stdout"}]},{"metadata":{"id":"NM6qKbyW9Sxd","colab_type":"code","colab":{},"trusted":true},"cell_type":"code","source":"import os\nbase_dir = '/kaggle/input/duth-cv-2019-2020-hw-4/vehicles'\ntrain_dir = os.path.join(base_dir, 'train')\nvalidation_dir = os.path.join(base_dir, 'val')","execution_count":16,"outputs":[]},{"metadata":{"id":"2RL4DHoz_oSs","colab_type":"code","outputId":"be273bda-b488-43d0-e6aa-2100bd5d21ae","colab":{"base_uri":"https://localhost:8080/","height":1000},"trusted":true},"cell_type":"code","source":"# Compile the model\nimport keras\nfrom keras.callbacks import ModelCheckpoint\nimport matplotlib.pyplot as plt\n\ncheckpoint = keras.callbacks.callbacks.ModelCheckpoint('model.hdf5', monitor='val_acc', verbose=1, save_best_only=True, save_weights_only=False, mode='max', period=1)\ncallbacks_list = [checkpoint]\nmodel.compile(loss='categorical_crossentropy',\n              optimizer=optimizers.RMSprop(lr=1e-4),\n              metrics=['acc'])\n# Train the model\nhistory = model.fit_generator(\n      train_generator,\n      steps_per_epoch=train_generator.samples/train_generator.batch_size,\n      epochs=4,\n      validation_data=validation_generator,\n      validation_steps=validation_generator.samples/validation_generator.batch_size,\n      verbose=1,\n      callbacks=callbacks_list)\n \n","execution_count":17,"outputs":[{"output_type":"stream","text":"Epoch 1/4\n125/124 [==============================] - 24s 189ms/step - loss: 1.0263 - acc: 0.6199 - val_loss: 0.2137 - val_acc: 0.7653\n\nEpoch 00001: val_acc improved from -inf to 0.76527, saving model to model.hdf5\nEpoch 2/4\n125/124 [==============================] - 23s 185ms/step - loss: 0.5491 - acc: 0.8264 - val_loss: 0.5528 - val_acc: 0.8296\n\nEpoch 00002: val_acc improved from 0.76527 to 0.82958, saving model to model.hdf5\nEpoch 3/4\n125/124 [==============================] - 23s 184ms/step - loss: 0.4108 - acc: 0.8709 - val_loss: 0.0476 - val_acc: 0.8617\n\nEpoch 00003: val_acc improved from 0.82958 to 0.86174, saving model to model.hdf5\nEpoch 4/4\n125/124 [==============================] - 23s 184ms/step - loss: 0.2823 - acc: 0.9166 - val_loss: 0.5035 - val_acc: 0.8875\n\nEpoch 00004: val_acc improved from 0.86174 to 0.88746, saving model to model.hdf5\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport os\nimport tensorflow as tf\nfrom keras.preprocessing import image\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nimport csv\n\nmodel = tf.keras.models.load_model('/kaggle/working/model.hdf5')\nrowlist = [['Id', 'Category']]\n\nfor dirname, _, filenames in os.walk('/kaggle/input/duth-cv-2019-2020-hw-4/vehicles/test'):\n    for filename in filenames:\n        path = os.path.join(dirname, filename)\n        img = image.load_img(path, target_size=(332,332), grayscale=False, interpolation='bilinear')\n        \n        x = image.img_to_array(img)\n        x = np.expand_dims(x, axis=0)\n        \n        classes_pred = model.predict(x)\n        cls_pred = np.argmax(classes_pred)\n        rowlist.append([filename, cls_pred])\n        #print(filename, cls_pred)\n        with open('output.csv', 'w', newline='') as file:\n            writer = csv.writer(file)\n            writer.writerows(rowlist)\n        ","execution_count":18,"outputs":[]}],"metadata":{"colab":{"name":"CV_2019-2020_Pretrained_Models_VGG.ipynb","provenance":[],"collapsed_sections":[],"toc_visible":true},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"nbformat":4,"nbformat_minor":1}